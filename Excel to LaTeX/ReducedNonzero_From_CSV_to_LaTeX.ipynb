{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Elyana Crowder Melnick\n",
    "#Last updated: 2/14/2025\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import Template\n",
    "import csv\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description: \n",
    "This code takes a single column version of the `TCL/Spin_Boson/Reduced_Nonzero_Terms.xlsx` spreadsheet, and converts it into a form more reasonable for typsetting. That is:\n",
    "The terms were initally grouped into single rows by their initial correlation terms, this code \n",
    "1) \"splits\" them into multiple lines\n",
    "\n",
    "2) Also considers direct additive cancellations between terms of different \"groups\" \n",
    "\n",
    "3) Translates from the shorthand notation used in the spreadsheet to LaTeX symbols\n",
    "\n",
    "The input for this a CSV, and the output is a `.txt` which contains an aligned equation that can be copy/pasted into a `.tex` file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShortHand_toTex(s):\n",
    "    #Types of terms: \n",
    "    # G -> \\Gamma\n",
    "    # GTat -> \\Gamma^T(a-t)\n",
    "    # Gat-Gtb -> \\Delta \\Gamma(a-t,t-b) \n",
    "    # * -> \\circ\n",
    "    \n",
    "    #1) find the gammas \n",
    "    #2) is it a delta gamma? (look to the right)\n",
    "    #3) is transposed?\n",
    "    #new sub, replace (convert times too)\n",
    "    #print(\"converting: \",s)\n",
    "    while \"G\" in s:\n",
    "        i_start = s.find(\"G\")\n",
    "        T_offset = 0\n",
    "        T_sub = \"\"\n",
    "        sign_offset = 0\n",
    "        if s[i_start+1] == \"T\":\n",
    "            #transposed case\n",
    "            T_offset = 1 #meaning, the transpose ofsets the times by this much: e.g. Gab versus GTab\n",
    "            T_sub = \"^T\"\n",
    "        t_s = decode_times(s[i_start+T_offset+1:i_start+T_offset+3]) \n",
    "        is_delta = False\n",
    "        sub_2 = \"\"\n",
    "        D_offset = 0\n",
    "        if s[i_start+T_offset+3] == \"-\":\n",
    "            is_delta = True\n",
    "            t_s2 = decode_times(s[i_start+(2*T_offset)+5:i_start+(2*T_offset)+7]) #need to check indexing\n",
    "            D_offset = 4+T_offset  #does include additional transpose if need\n",
    "            # e.g. from len being Gab (3) [or GTab (3+T_offset)] to Gab-Gab (7) or GTab-GTba (9)\n",
    "        if is_delta: \n",
    "            new_sub = \"\\Delta\\gamma\"+T_sub+\"(\"+t_s+\",\"+t_s2+\")\"\n",
    "        else: \n",
    "            #is there a leading sign?\n",
    "            new_sub = \"\\gamma\"+T_sub+\"(\"+t_s+\")\"\n",
    "            if s[i_start - 1] == \"-\":\n",
    "                new_sub = \"(-\" + new_sub+\")\"\n",
    "                sign_offset = 1\n",
    "            \n",
    "        #replacing it: \n",
    "        s = s[0:i_start-(1+sign_offset)]+new_sub+s[i_start+4+T_offset+D_offset:] #part before + newsub + part after\n",
    "        \n",
    "    #Now, rewriting the system operators: \n",
    "    #finding, a,b where i_start -1 is not _\n",
    "    #NOW, using regex:\n",
    "    #(?<!_)[ab] negative lookbehind assertion\n",
    "   \n",
    "    aops = re.compile(\"(?<![_gmth{])a\")#pattern\n",
    "    bops = re.compile(\"(?<![_gmth{])b\")#pattern\n",
    "    s = re.sub(aops, r\"\\\\hat{a}\", s)\n",
    "    s = re.sub(bops, r\"\\\\hat{b}\", s)\n",
    "    s = s.replace(\"0\",\"\\hat{0}\")\n",
    "    s = s.replace(\"p\", r\"\\hat{\\varrho}\")\n",
    "    s = s.replace(\"*\",r\"\\circ\")\n",
    "    #Last step: switch gammas to Gammas\n",
    "    s = s.replace(\"\\gamma\", \"\\Gamma\")\n",
    "    return s\n",
    "\n",
    "\n",
    "def decode_times(s):\n",
    "    #given string of two characters, translate into latex\n",
    "    #a -> t_a\n",
    "    #t -> t\n",
    "    #b -> t_b\n",
    "    # 0  = 0 \n",
    "    #anything with zero second, the zero shoudl be omitted e.g a0 -> t_a NOT t_a - 0\n",
    "    res = \"\"\n",
    "    subscripts = [\"a\",\"b\"]\n",
    "    if s[0] in subscripts:\n",
    "        t_1 = \"t_\"+s[0]\n",
    "    else:\n",
    "        t_1 = s[0]\n",
    "        \n",
    "    if s[1] in subscripts:\n",
    "        t_2 = \"t_\"+s[1]\n",
    "    else:\n",
    "        t_2 = s[1]\n",
    "        \n",
    "    if s[0] == \"0\":\n",
    "        res = \"-\"+t_2\n",
    "    elif s[1] == \"0\":\n",
    "        res = t_1\n",
    "    else:\n",
    "        res = t_1+\"-\"+t_2        \n",
    "    return res\n",
    "\n",
    "def bounds_to_tex(s,TCL4=False):\n",
    "    # eg. +(0ta)(0ab)\n",
    "    if TCL4:\n",
    "        res =  r\"\\int_{{t_{0[2]}}}^{{t_{0[3]}}}dt_{0[4]}\".format(s)\n",
    "    else:\n",
    "        res =  r\"\\int_{{t_{0[2]}}}^{{t_{0[3]}}}dt_{0[4]}\\int_{{t_{0[7]}}}^{{t_{0[8]}}}dt_{0[9]}\".format(s)\n",
    "    res = res.replace(\"t_0\",\"0\")\n",
    "    res = res.replace(\"t_t\",\"t\")\n",
    "    return s[0]+res\n",
    "\n",
    "def merger_integral(b,s):\n",
    "    #note, original entries has -[0,] omitted\n",
    "    #outdated, do not use\n",
    "    signed = 1\n",
    "    if b[0] == \"-\" and s[0] == \"-\":\n",
    "        sign = \"&-\"\n",
    "    elif b[0] == \"-\" or s[0] == \"-\":\n",
    "        sign = \"&+\"\n",
    "    else: \n",
    "        sign = \"&-\"\n",
    "    if s[0] not in [\"+\",\"-\"]: \n",
    "        signed = 0 #integrand has no leading sign\n",
    "    return sign+b[1:]+\"[\\hat{0},\"+s[signed:]+r\"]\\\\\"\n",
    "\n",
    "#want to instead, factor out the overall integral: +(0ta)(0ab), thus make sure each integrand has it's own sign\n",
    "\n",
    "def factor_signs(b,i,update=True):\n",
    "    # single row, NON DISTRIBUTIVE, assuming rows have already been split! \n",
    "    if b[0] == \"-\":\n",
    "        #need to move negative over \n",
    "        if i[0] == \"-\":\n",
    "            i = \"+\"+i[1:]\n",
    "        elif i[0] == \"+\":\n",
    "                i = \"-\" + i[1:]\n",
    "        else: \n",
    "            i = \"-\" + i\n",
    "    if i[0] != \"+\" and i[0] !=\"-\":\n",
    "        #i implicitly positive\n",
    "        i = \"+\"+ i\n",
    "    b = \"+\"+b[1:]\n",
    "    if update:\n",
    "        return i\n",
    "    else:\n",
    "        return b\n",
    "#how to determine integrands that can be split (withough expanding commutators)\n",
    "# print(s)\n",
    "# print(\"number of terms with rho:\", s.count(\"p\"))\n",
    "#define:\n",
    "#for an indepenent term, all of the left square brackets are closed: \n",
    "#basically, for each \"+,-\" check if brackets before are all closed and if there is a p factor (there should be )\n",
    "\n",
    "def valid_Parens(s):\n",
    "    #like the LeetCode problem...\n",
    "    #but first remove non brackets\n",
    "    non_bracket = re.compile(\"[^][{}()]\")\n",
    "    s = re.sub(non_bracket,\"\",s)\n",
    "    if len(s)== 0:\n",
    "        return False\n",
    "\n",
    "    o = [\"[\",\"(\",\"{\"]\n",
    "    c = [\"]\",\")\",\"}\"]\n",
    "    stack = []\n",
    "    #need to verify equal numbers:\n",
    "    counts = {\"open\" :[s.count(k) for k in o], \"close\":[s.count(k) for k in c]}\n",
    "    if counts[\"open\"] != counts[\"close\"]:\n",
    "#         print(\"unequal brackets\")\n",
    "        return False\n",
    "    else:\n",
    "        if s[0] in c: #starts with closing\n",
    "            return False\n",
    "        else:\n",
    "            for b in s:\n",
    "                if b in o:\n",
    "                    stack.append(b)\n",
    "                else: #closing\n",
    "                    if len(stack) == 0:\n",
    "                        return False\n",
    "                    else:\n",
    "                        last_elt = stack.pop()\n",
    "                        if  last_elt != o[c.index(b)]:\n",
    "                            return False\n",
    "    return True\n",
    " \n",
    "def row_splitter(row,flag=False): #debugged\n",
    "    \n",
    "    if type(row) == list: \n",
    "        return row\n",
    "    s_split = []\n",
    "    matches = re.finditer(re.compile(\"(-)|(\\+)\"),row)\n",
    "    temp_ind = 0\n",
    "    for m in matches:\n",
    "#         print(\"-------------------------------\")\n",
    "#         print(m.start(0),row[m.start(0)], row[m.start(0)-1:m.start(1)+1])\n",
    "        sub = row[temp_ind:m.start(0)] \n",
    "#         print(\"sub = \",sub)\n",
    "        #m.start(0) index of addition/subtraction\n",
    "        if valid_Parens(sub) and \"p\" in sub:\n",
    "            if flag:\n",
    "                print(\"found\")\n",
    "            temp_ind = m.start(0)\n",
    "            s_split.append(sub)\n",
    "    s_split.append(row[temp_ind:])\n",
    "    return s_split\n",
    "\n",
    "def check_cancel(I):\n",
    "    if len(I) != 2:\n",
    "        return False\n",
    "    else:\n",
    "        res = 1\n",
    "        for elt in I:\n",
    "            res = res*int(elt[0]+\"1\") \n",
    "        return res < 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Row splitting (v2): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of lines: 80  | maximum line length:  287\n",
      "number of lines after automated splitting: 201  | maximum line length:  82\n"
     ]
    }
   ],
   "source": [
    "excel = pd.read_csv(\"./Reduced_Nonzero_Terms_CSV.csv\",header=0,names=[\"C\",\"bounds\",\"integrand\"])\n",
    "#print(excel)\n",
    "#print(excel.shape[0]) #current number of \"lines\" = 80\n",
    "\n",
    "line_lens = excel.integrand.apply(lambda x: len(x))#number of characters in each line, just to check. \n",
    "print(\"number of lines:\",excel.shape[0],\" | maximum line length: \", max(line_lens)) #need maximum to be less than approximately 60  \n",
    "#splitting the unprocessed rows\n",
    "\"\"\"By identifying [[,()]] complete closed parenthesis terms.\n",
    "   E.g. Each row is like [A] = [B + C] => [B,C]\n",
    "   This does not foil and split terms like [A(B + C)] => [AB,AC] \"\"\"\n",
    "excel.integrand  = excel.integrand.apply(row_splitter) \n",
    "excel = excel.explode(\"integrand\",ignore_index=True) #making new rows with split terms\n",
    "\n",
    "line_lens = excel.integrand.apply(lambda x: len(x))#number of characters in each line, just to check. \n",
    "print(\"number of lines after automated splitting:\",excel.shape[0], \" | maximum line length: \", max(line_lens)) #need maximum to be less than approximately 60  \n",
    "\n",
    "#moving negative bound signs to integrand (must do AFTER splitting, since apply outer parens in some cases)\n",
    "excel[\"integrand\"] = excel.apply(lambda x: factor_signs(x.bounds,x.integrand,True),axis=1) #update integrand signs\n",
    "excel[\"bounds\"] = excel.apply(lambda x: factor_signs(x.bounds,x.integrand,False),axis=1) #update integrand signs\n",
    "#print(excel.to_string())\n",
    "#converting integrands to latex \n",
    " \n",
    "excel.to_excel(\"./Automated_splits_TCL6.xlsx\") # Saving to excel intermediately\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Hardcoded factorization splits for TCL6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of lines after extra splits:  207  | new maximum line length:  55\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#There are a few terms that are written as A(B + C) that need to be seperated still, at indices \n",
    "#4,7,115,118,186,189\n",
    "#This are identifable since they have more than one \"p\" (\\rho), and are very noticible in the spreadsheet\n",
    "#Will hardcode in the splits here (based on string searches, but not generalized)\n",
    "#ind = 4, k = 20, m = 50. For A(B+C), k is the index of \"(\"+1 and m is the index of \"+\"+1\n",
    "#ind = 7, k = 20, m = 50\n",
    "#ind 115, k = 20, m = 51\n",
    "#ind 118, k = 20, m = 49\n",
    "#ind 186, k = 32, m = 54\n",
    "#ind 189, k = 34, m = 54\n",
    "manual_splits = [[4,20,50],\n",
    "                 [7,20,50],\n",
    "                 [115,20,51],\n",
    "                 [118,20,49],\n",
    "                 [186,32,54],\n",
    "                 [189,34,54]] #hardcoded, instead of opening up the spreadsheet [ind,k,m]\n",
    "for [ind,k,m] in manual_splits:\n",
    "    row_i = excel.loc[ind,'integrand']\n",
    "    #check signs\n",
    "    s_C = row_i[0]\n",
    "    if row_i[m] == \"-\":\n",
    "        if row_i[0] == \"+\":\n",
    "            s_C = \"-\"\n",
    "        else: \n",
    "            s_C = \"+\"\n",
    "    rows_i = [row_i[0:k]+row_i[k+1:m],s_C+row_i[1:k]+row_i[m+1:-1]]\n",
    "    #print(rows_i)\n",
    "    excel.integrand[ind] = rows_i\n",
    "excel = excel.explode(\"integrand\",ignore_index=True) #making new rows with split terms, this DOES shift, indices\n",
    "excel.to_excel(\"./Automated_splits_andHardcode_TCL6.xlsx\")\n",
    "line_lens = excel.integrand.apply(lambda x: len(x))#number of characters in each line, just to check. \n",
    "#print(\"new maximum line length\", max(line_lens)) #need maximum to be less than approximately 60  \n",
    "print(\"number of lines after extra splits: \", excel.shape[0],\" | new maximum line length: \", max(line_lens))\n",
    "#plt.plot(line_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row cancellations\n",
    "Removing rows +A such that -A is also a row.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "excel[\"unsigned\"] = excel.integrand.apply(lambda x: x[1:]) #add new column, with sign removed\n",
    "cancelled = excel.groupby(\"unsigned\").filter(lambda x: check_cancel(x[\"integrand\"])) #will store in seperate df\n",
    "excel = excel.groupby(\"unsigned\").filter(lambda x: not check_cancel(x[\"integrand\"]))\n",
    "\n",
    "  \n",
    "cancelled.to_excel(\"./ListofCanceledRows_aftersplits_TCL6.xlsx\") # Saving to excel intermediately\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full processing after row cancellations (auto and manual) (v3): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#converting integrands to latex \n",
    "excel.integrand = excel.integrand.apply(ShortHand_toTex)\n",
    "excel.bounds= excel.bounds.apply(bounds_to_tex) #(also integration bounds)\n",
    "\n",
    "  \n",
    "excel.to_excel(\"./Cancellations_splits_TCL6.xlsx\") # Saving to excel intermediately    \n",
    "\n",
    "#finally, want to group by original correlation function, \n",
    "#make caption the correlation function, and header, make it the actual element\n",
    "#final_df.to_csv(\"ReducedEqns_tex.csv\",sep=\"\\n\",header=False, index=False,quoting=csv.QUOTE_NONE)\n",
    "#options: sep=\"\\n\",header=G.bounds[0]+, columns = \"Integrand\", index=False,quoting=csv.QUOTE_NONE, mode = 'a'\n",
    "filename = \"Grouped_Split_ReducedEqns_v4.txt\"\n",
    "head = r\"\\begin{align}\\text{TCL6} &= -\\Big{[}\\hat{0},\"+excel.bounds[0][1:]+r\"\\\\\"\n",
    "f = open(filename, \"w+\")\n",
    "f.write(head)\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "#add closing bracket and newline element to integrands\n",
    "excel.integrand = excel.integrand.apply(lambda x: \"&\"+x+r\"\\\\\")\n",
    "\n",
    "for CorrFuns,sub_table in excel.groupby(\"C\"):\n",
    "    f = open(filename, \"a\")\n",
    "    #f.write(r\"\\begin{align}\")\n",
    "    f.write(r\"%\"+CorrFuns)\n",
    "    f.write('\\n')\n",
    "    f.close()\n",
    "    #sub_table.to_csv(filename,sep=\"\\n\",header=[CorrFuns+head], columns = [\"integrand\"],index=False,quoting=csv.QUOTE_NONE, mode = 'a')\n",
    "    sub_table.to_csv(filename,sep=\"\\n\",header=None, columns = [\"integrand\"],index=False,quoting=csv.QUOTE_NONE, mode = 'a')\n",
    "f = open(filename, \"a\")\n",
    "f.write(r\"\\Big{]} + h.c. \\end{align} \")\n",
    "f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
